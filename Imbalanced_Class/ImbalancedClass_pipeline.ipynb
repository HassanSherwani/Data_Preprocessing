{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qp6Jzx49W_ta"
   },
   "source": [
    "# Treating imbalanced Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1)-Importing key modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4V11g1goXDyF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# For processing\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from collections import Counter\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "plt.rcParams[\"figure.figsize\"] = (16, 10)\n",
    "plt.rcParams[\"xtick.labelsize\"] = 10\n",
    "plt.figure(figsize=(16,10)) # this creates a figure 16 inch wide, 10 inch high\n",
    "from pprint import pprint\n",
    "%matplotlib inline\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For modeling building and tunning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.preprocessing import Imputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# for evaluation\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.metrics import recall_score, f1_score\n",
    "from sklearn.metrics import classification_report,roc_auc_score, roc_curve\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for class imbalnce\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2)-Loading data\n",
    "\n",
    "Data loaded from previous work. \n",
    "\n",
    "Case of end customers' travelling behavior from online system "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45805, 515)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('selected_feature.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_type</th>\n",
       "      <th>distance</th>\n",
       "      <th>num_family</th>\n",
       "      <th>len_jour</th>\n",
       "      <th>ts_hour</th>\n",
       "      <th>origin_ADB</th>\n",
       "      <th>origin_ADL</th>\n",
       "      <th>origin_AER</th>\n",
       "      <th>origin_AGP</th>\n",
       "      <th>origin_AKL</th>\n",
       "      <th>...</th>\n",
       "      <th>dest_YEG</th>\n",
       "      <th>dest_YMQ</th>\n",
       "      <th>dest_YOW</th>\n",
       "      <th>dest_YTO</th>\n",
       "      <th>dest_YUL</th>\n",
       "      <th>dest_YVR</th>\n",
       "      <th>dest_YWG</th>\n",
       "      <th>dest_YYC</th>\n",
       "      <th>dest_YYZ</th>\n",
       "      <th>dest_ZRH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5834.154716</td>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6525.926149</td>\n",
       "      <td>4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>469.781624</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1498.817537</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2921.339028</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 515 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_type     distance  num_family  len_jour  ts_hour  origin_ADB  \\\n",
       "0           0  5834.154716           7       6.0       11           0   \n",
       "1           1  6525.926149           4      21.0       20           0   \n",
       "2           1   469.781624           2       3.0       23           0   \n",
       "3           1  1498.817537           1       3.0       15           0   \n",
       "4           1  2921.339028           4       6.0       22           0   \n",
       "\n",
       "   origin_ADL  origin_AER  origin_AGP  origin_AKL  ...  dest_YEG  dest_YMQ  \\\n",
       "0           0           0           0           0  ...         0         0   \n",
       "1           0           0           0           0  ...         0         0   \n",
       "2           0           0           0           0  ...         0         0   \n",
       "3           0           0           0           0  ...         0         0   \n",
       "4           0           0           0           0  ...         0         0   \n",
       "\n",
       "   dest_YOW  dest_YTO  dest_YUL  dest_YVR  dest_YWG  dest_YYC  dest_YYZ  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "\n",
       "   dest_ZRH  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 515 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- event_type is our target variable.\n",
    "- 1 means booking activity\n",
    "- 0 means searching activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    43997\n",
       "1     1808\n",
       "Name: event_type, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.event_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.960528\n",
       "1    0.039472\n",
       "Name: event_type, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.event_type.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our target variable with only 3% of class 1 i.e class of our interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3)-Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1)- Separate X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=df[\"event_type\"]\n",
    "features=df.drop(['event_type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45805,)\n",
      "(45805, 514)\n"
     ]
    }
   ],
   "source": [
    "print(target.shape)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2)- Normalize data\n",
    "\n",
    "This will take care of those spike values in variables like distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = StandardScaler().fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3)-train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32063, 514)\n",
      "(13742, 514)\n",
      "(32063,)\n",
      "(13742,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4)-Applying Logistic Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=1e5)\n",
    "logreg.fit(X_train, y_train)\n",
    "predictions_LR = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9598311745015282\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,predictions_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     13217\n",
      "           1       0.03      0.00      0.00       525\n",
      "\n",
      "    accuracy                           0.96     13742\n",
      "   macro avg       0.50      0.50      0.49     13742\n",
      "weighted avg       0.93      0.96      0.94     13742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions_LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy score is good but, is it enough? Looking at recall, precision does not seem to be case where search class is doing very well but, booking event type class is poor. This is where we say that accuracy isn't a good matrics to evaluate our model.\n",
    "\n",
    "There are two problems here.\n",
    "\n",
    "- 1- Imbalnced class \n",
    "- 2- Selecting correct evaluation matric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's review event_type again\n",
    "\n",
    "booking = df[df['event_type']==1]\n",
    "\n",
    "search = df[df['event_type']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1808, 515)\n",
      "(43997, 515)\n"
     ]
    }
   ],
   "source": [
    "print(booking.shape)\n",
    "print(search.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Book class has only 3.9 % of values i.e 1808. This is why our model did well for accuracy. As accuracy is overall picture how model predicts correct values. Unfortunately those correct values are search class samples. We are interested in onversion likelihood i.e search to booking cases. \n",
    "\n",
    "Luckily, there is solution to this "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4)- Solving imbalnced Class Problem\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(headline, true_value, pred):\n",
    "    print(headline)\n",
    "    print(\"precision: {}\".format(precision_score(true_value, pred)))\n",
    "    print(\"recall: {}\".format(recall_score(true_value, pred)))\n",
    "    print(\"f1: {}\".format(f1_score(true_value, pred)))\n",
    "    print(\"f1: {}\".format(f1_score(true_value, pred)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We shall use make_pipe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build normal model (we already have done that yet doing it again)\n",
    "pipeline = make_pipeline(classifier(random_state=42))\n",
    "model = pipeline.fit(X_train, y_train)\n",
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model with undersampling\n",
    "nearmiss_pipeline = make_pipeline_imb(NearMiss(), classifier(random_state=42))\n",
    "nearmiss_model = nearmiss_pipeline.fit(X_train, y_train)\n",
    "nearmiss_prediction = nearmiss_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model with SMOTE imblearn\n",
    "smote_pipeline = make_pipeline_imb(SMOTE(), classifier(random_state=42))\n",
    "smote_model = smote_pipeline.fit(X_train, y_train)\n",
    "smote_prediction = smote_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "normal data distribution: Counter({0: 43997, 1: 1808})\n",
      "SMOTE data distribution: Counter({0: 43997, 1: 43997})\n",
      "NearMiss data distribution: Counter({0: 1808, 1: 1808})\n"
     ]
    }
   ],
   "source": [
    "# print information about three models\n",
    "print()\n",
    "print(\"normal data distribution: {}\".format(Counter(target)))\n",
    "X_smote, y_smote = SMOTE().fit_sample(X, target)\n",
    "print(\"SMOTE data distribution: {}\".format(Counter(y_smote)))\n",
    "X_nearmiss, y_nearmiss = NearMiss().fit_sample(X, target)\n",
    "print(\"NearMiss data distribution: {}\".format(Counter(y_nearmiss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     13217\n",
      "           1       0.00      0.00      0.00       525\n",
      "\n",
      "    accuracy                           0.96     13742\n",
      "   macro avg       0.48      0.50      0.49     13742\n",
      "weighted avg       0.93      0.96      0.94     13742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.97      0.55      0.58      0.70      0.57      0.32     13217\n",
      "          1       0.05      0.58      0.55      0.09      0.57      0.32       525\n",
      "\n",
      "avg / total       0.94      0.55      0.58      0.68      0.57      0.32     13742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print(classification_report_imbalanced(y_test, smote_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.accuracy sore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "normal Pipeline Score 0.961650414786785\n",
      "SMOTE Pipeline Score 0.5510114975986028\n",
      "NearMiss Pipeline Score 0.22165623635569787\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print('normal Pipeline Score {}'.format(pipeline.score(X_test, y_test)))\n",
    "print('SMOTE Pipeline Score {}'.format(smote_pipeline.score(X_test, y_test)))\n",
    "print('NearMiss Pipeline Score {}'.format(nearmiss_pipeline.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.precision, recall & f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "normal classification\n",
      "precision: 0.0\n",
      "recall: 0.0\n",
      "f1: 0.0\n",
      "f1: 0.0\n",
      "\n",
      "SMOTE classification\n",
      "precision: 0.04890522614671568\n",
      "recall: 0.5828571428571429\n",
      "f1: 0.09023886759068121\n",
      "f1: 0.09023886759068121\n",
      "\n",
      "NearMiss classification\n",
      "precision: 0.03552835875422413\n",
      "recall: 0.7409523809523809\n",
      "f1: 0.06780547324385568\n",
      "f1: 0.06780547324385568\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print_results(\"normal classification\", y_test, prediction)\n",
    "print()\n",
    "print_results(\"SMOTE classification\", y_test, smote_prediction)\n",
    "print()\n",
    "print_results(\"NearMiss classification\", y_test, nearmiss_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 1:\n",
      "Accuracy: 0.5895644580285995\n",
      "f-score: 0.2407108239095315\n",
      "For fold 2:\n",
      "Accuracy: 0.5776661936469818\n",
      "f-score: 0.02617669267556003\n",
      "For fold 3:\n",
      "Accuracy: 0.5786486191463814\n",
      "f-score: 0.0\n",
      "For fold 4:\n",
      "Accuracy: 0.5788669359240257\n",
      "f-score: 0.0005181347150259067\n",
      "For fold 5:\n",
      "Accuracy: 0.5894552996397773\n",
      "f-score: 0.0010624169986719787\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "    X_train = X[train_index]\n",
    "    y_train = target[train_index]  # Based on your code, you might need a ravel call here, but I would look into how you're generating your y\n",
    "    X_test = X[test_index]\n",
    "    y_test = target[test_index]  # See comment on ravel and  y_train\n",
    "    sm = SMOTE()\n",
    "    X_train_oversampled, y_train_oversampled = sm.fit_sample(X_train, y_train)\n",
    "    model = LogisticRegression()  # Choose a model here\n",
    "    model.fit(X_train_oversampled, y_train_oversampled )  \n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f'For fold {fold}:')\n",
    "    print(f'Accuracy: {model.score(X_test, y_test)}')\n",
    "    print(f'f-score: {f1_score(y_test, y_pred)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross validation done wrong\n",
    "\n",
    "- Thanks to https://www.youtube.com/watch?v=DQC_YE3I5ig tutorial, I have found what is right and what is wrong way to apply K-fold.\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=42) <br>\n",
    "accuracy = [] <br>\n",
    "precision = [] <br>\n",
    "recall = [] <br>\n",
    "f1 = [] <br>\n",
    "auc = [] <br>\n",
    "X, y = SMOTE().fit_sample(X_train, y_train) <br>\n",
    "for train, test in kf.split(X, y): <br>\n",
    "    pipeline = make_pipeline(classifier(random_state=42)) <br>\n",
    "    model = pipeline.fit(X[train], y[train]) <br>\n",
    "    prediction = model.predict(X[test]) <br>\n",
    "    accuracy.append(pipeline.score(X[test], y[test])) <br>\n",
    "    precision.append(precision_score(y[test], prediction)) <br>\n",
    "    recall.append(recall_score(y[test], prediction)) <br>\n",
    "    f1.append(f1_score(y[test], prediction)) <br>\n",
    "\n",
    "print(\"done wrong mean of scores 5-fold:\") <br>\n",
    "print(\"accuracy: {}\".format(np.mean(accuracy))) <br>\n",
    "print(\"precision: {}\".format(np.mean(precision))) <br>\n",
    "print(\"recall: {}\".format(np.mean(recall))) <br>\n",
    "print(\"f1: {}\".format(np.mean(f1))) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ldvDx7DPUErC"
   },
   "source": [
    "**END OF NOTEBOOK**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "3.Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
